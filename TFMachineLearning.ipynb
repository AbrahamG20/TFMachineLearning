{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TFMachineLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VyP2voxKvz4r",
        "DUJz9Qy5vz4s",
        "QqmcgP9Cvz4s",
        "A4eCb6CZvz4s",
        "7QZMM4tGvz4t",
        "LCNSTjPpvz4t"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn6wZMevvz4p"
      },
      "source": [
        "# Trabajo Parcial 2\n",
        "## 1.Inicializando Librerías\n",
        "Para realizar nuestro trabajo utilizaremos las siguientes librerías: Usaremos Numpy para poder utilizar su estructura de arreglos; con Matplotlib graficaremos la información de forma más sencilla. Por último, utilizaremos pandas para poder leer el dataset propuesto por el trabajo y para almacenarlo en su estructura de dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV0SxwJpvz4p"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVGM1SGqvz4p"
      },
      "source": [
        "## 2.Lectura del Dataset\n",
        "El trabajo propuesto por el curso de machine learning nos plantea entrenar un modelo que pueda clasificar correctamente si un correo electrónico es de categoria spam o lo contrario. Para ello se nos entregó un dataset clasico de SPAM OR NOT SPAM, que contiene 2500 'ham' (es decir, no spam) y 500 correos electrónicos no deseados en el conjunto de datos. También puede notar que todos los números y URL se convirtieron en cadenas como NUMBER y URL respectivamente. Este es el conjunto de datos simplificado de spam y ham. Este dataset contiene las siguientes variables:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu7Q6AcUvz4p"
      },
      "source": [
        "df = pd.read_csv('dataset.csv', encoding = \"ISO-8859-1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFhLrr0Tvz4p"
      },
      "source": [
        "Una vez hayamos cargado el dataset, procedemos a visualizar los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb1etoN0vz4p"
      },
      "source": [
        "## 3. Análisis Exploratorio y Tratamiento de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMa5o3f0vz4p"
      },
      "source": [
        "### 3.1- Visualizacion Corta del Dataframe\n",
        "Lo primero que se decidió hacer fue ver el estado del dataframe, por lo que usamos la función head() de pandas. Se puede visualizar todas las columnas, y las primeras 5 filas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeOC02uUvz4p"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok9vomJTvz4q"
      },
      "source": [
        "### 3.2- Magnitud del Dataset\n",
        "Luego, para tener una idea de la magnitud del dataset con el que se está trabajando, usamos la función shape() de Pandas para que nos retorne el número de filas y columnas de dicho dataset. El primer axis son el numero de filas y la segunda de las columnas. Tambien mostraremos como estan estructurados nuestros datos. Es decir la distribución de los valores del dominio de nuestro dataset; 0 para no SPAM y 1 para SPAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmlmXbGxvz4q"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tuku6X83vz4q"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W26qTpkIvz4r"
      },
      "source": [
        "df.hist();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH57ZTKdqOOn"
      },
      "source": [
        "spam = df[df['label']== 1]\n",
        "spam.head()\n",
        "\n",
        "ham = df[df['label']== 0]\n",
        "ham.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z0maf9UqOOn"
      },
      "source": [
        "text_spam = \" \".join(str(review) for review in spam.email)\n",
        "\n",
        "wordcloud = WordCloud().generate(text_spam)\n",
        "\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbRgAApvqOOn"
      },
      "source": [
        "text_ham = \" \".join(review for review in ham.email)\n",
        "\n",
        "wordcloud = WordCloud().generate(text_ham)\n",
        "\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4xa8T2Bvz4r"
      },
      "source": [
        "### 3.3 - Valores Nulos\n",
        "Es un paso crucial ver si existen valores nulos en el dataset que se va a usar,por lo tanto, usando la función isna(), mas sumando todo con sum(), podemos sumar la cantidad de valores nulos por cada columnas de DF. En este caso, podemos ver que la de los correos tiene 1 valor unico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndfZ2hyXvz4r"
      },
      "source": [
        "df.isna().sum() #Detección de valores nulos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyP2voxKvz4r"
      },
      "source": [
        "### 3.4 Tipos de Atributos\n",
        "Es muy importante, antes de empezar a trabajar con la data de un dataset, saber qué tipos de atributos contiene. Para esto, se hizo uso de la función dtypes() de pandas, que , por cada columna, me retorna su tipo de dato."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32TK1Kvcvz4r"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i81Tjtj0vz4s"
      },
      "source": [
        "\n",
        "Podemos ver que la columna importante de 'email' esta en tipo Object, lo que nos dice que el dataset no está listo para poder entrenarlo. Esto se arreglara posteriormente.\n",
        "\n",
        "Para poder ver las estadísticas de las columnas numéricas, se hizo uso de la función describe() de pandas una vez más. Como podemos ver, solo toma en cuenta las columnas que están en tipos numéricos, es decir int o float. En este caso es solo los labels (clases)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n7kulZGvz4s"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUJz9Qy5vz4s"
      },
      "source": [
        "### 3.5 Distribución Aleatoria de los datos\n",
        "Usando la función Shuffle de Sklearn distribuiremos los datos para que los datos no esten ordenados y podemos partirlos posteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh-5nCFsvz4s"
      },
      "source": [
        "df = shuffle(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZe6P_H0vz4s"
      },
      "source": [
        "## 4 - Tratamiento de Datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqmcgP9Cvz4s"
      },
      "source": [
        "### 4.1 - Descartando Valores Faltantes\n",
        "Como se analizó previamente, en la sección de exploración de datos, había un registro con valor nulo en la columna de 'email'. Para solucionar esto, como nos dimos cuenta que habían suficientes registros en el dataset, y que solo era un registro, decidimos descartar esa filas que contenía dicho valor nulo. Entonces, lo que decidimos hacer fue usar la funcion dropna() de libreria Pandas, que fue cargada previamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_nUNGMDvz4s"
      },
      "source": [
        "df = df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUZ4FDq6vz4s"
      },
      "source": [
        "Hacemos una simple verificacion que efectivamente se borro el registro nulo y podemos ver que efectivamente lo hizo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwgCLKYivz4s"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfMXXzk7qOOo"
      },
      "source": [
        "### 4.2 - Data Cleaning and preparation\n",
        "\n",
        "Partimos el dataset en data de entrenamiento y de prueba para poder empezar a enviarlos a los modelos escogidos dentro del alcance de este trabajo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Ow5dBZj7in"
      },
      "source": [
        "x = []\n",
        "y = []\n",
        "for index,row in df.iterrows():\n",
        "  df['email'][index] = df['email'][index].replace('NUMBER','')\n",
        "  df['email'][index] = df['email'][index].replace('hyperlink','')\n",
        "  df['email'][index] = df['email'][index].replace('URL','')\n",
        "\n",
        "  df['email'][index] = df['email'][index].replace(r'\\r', ' ')\n",
        "  df['email'][index] = df['email'][index].replace(r'\\n', ' ')\n",
        "  df['email'][index] = df['email'][index].replace('[^a-zA-Z0-9]', ' ')\n",
        "\n",
        "  x.append(df['email'][index])\n",
        "  y.append(df['label'][index])\n",
        "\n",
        "print(len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtzVxFafnubb"
      },
      "source": [
        "spam = df[df['label']== 1]\n",
        "spam.head()\n",
        "\n",
        "ham = df[df['label']== 0]\n",
        "ham.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlwbwFaqkuHg"
      },
      "source": [
        "text_spam = \" \".join(str(review) for review in spam.email)\n",
        "\n",
        "wordcloud = WordCloud().generate(text_spam)\n",
        "\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy5DBYHekweZ"
      },
      "source": [
        "text_ham = \" \".join(review for review in ham.email)\n",
        "\n",
        "wordcloud = WordCloud().generate(text_ham)\n",
        "\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAej5HwAqOOo"
      },
      "source": [
        "# x = []\n",
        "# y = []\n",
        "# for index, row in df.iterrows():\n",
        "#         row_aux = row[0].lower()\n",
        "#         row_aux = row_aux.replace(r'\\r', ' ')\n",
        "#         row_aux = row_aux.replace(r'\\n', ' ')\n",
        "#         row_aux = row_aux.replace('[^a-zA-Z0-9]', ' ')\n",
        "\n",
        "#         x.append(row_aux)\n",
        "#         y.append(row[1])\n",
        "\n",
        "# print(len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdLC0Zl2s_XV"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBpnpXtxqOOo"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2,random_state=0, shuffle = True)\n",
        "print(len(x_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4eCb6CZvz4s"
      },
      "source": [
        "### 4.2 - Bag of Words \n",
        "Descripcion aqui y mas floro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3tHk-hBLXnH"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vec = TfidfVectorizer()#ngram_range=(1,1),stop_words='english')\n",
        "x_train_data = vec.fit_transform(x_train)\n",
        "x_train_df = pd.DataFrame(data = x_train_data.toarray(),\n",
        "columns=vec.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApZzOmHnqOOo"
      },
      "source": [
        "x_train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgInA1VhLXnH"
      },
      "source": [
        "### 4.3 - PCA\n",
        "\n",
        "Disminuiremos el número de columnas, con fin de buscar optimizar los tiempos de ejecución de nuestros modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U6Dbuf0LXnH"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA().fit(x_train_df)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Componentes')\n",
        "plt.ylabel('Variancia Acumulada Explicada');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3gyAjesLXnI"
      },
      "source": [
        "pca = PCA(n_components=1000)\n",
        "principalComponents = pca.fit_transform(x_train_df)\n",
        "x_train_w_pca = pd.DataFrame(data = principalComponents)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgULwRd5vz4t"
      },
      "source": [
        "## 5. - Elección de Modelos a Utilizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX95xWUF0fBT",
        "outputId": "ae0a7679-cfa0-4099-95c7-d1ba4aaabf7a"
      },
      "source": [
        "svm_pred = clf_svm.predict(x_test)\n",
        "accuracy_score(y_test, svm_pred)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9733333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QZMM4tGvz4t"
      },
      "source": [
        "### 5.1 - K-Nearest Neighbors Model\n",
        "Se seleccionó el algoritmo KNN porque es uno de los algoritmos de clasificación más simples y es uno de los algoritmos de aprendizaje más utilizados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlHQA_-mvz4t"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "neighbors = 0\n",
        "clf_knn = Pipeline([('tfidf', TfidfVectorizer()),('Knn', KNeighborsClassifier(n_neighbors=neighbors))])\n",
        "clf_knn.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVYModBALXnI"
      },
      "source": [
        "acc = []\n",
        "\n",
        "for i in range(1,40):\n",
        "    clf_knn_aux = Pipeline([('tfidf', TfidfVectorizer()),('Knn', KNeighborsClassifier(n_neighbors=i))])\n",
        "    clf_knn_aux.fit(x_train, y_train)\n",
        "    # neigh = KNeighborsClassifier(n_neighbors = i).fit(x_train_w_pca,y_train)\n",
        "    y_pred = clf_knn_aux.predict(x_test)\n",
        "    acc.append(accuracy_score(y_test, y_pred))\n",
        "    \n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,40),acc,color = 'blue',linestyle='dashed', \n",
        "         marker='o',markerfacecolor='red', markersize=10);\n",
        "plt.title('accuracy vs. K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Accuracy')\n",
        "print(\"Maximum accuracy:\",max(acc),\"at K =\",acc.index(max(acc))+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSyDKX0vLXnI"
      },
      "source": [
        "clf_knn_mod = Pipeline([('tfidf', TfidfVectorizer()),('Knn', KNeighborsClassifier(n_neighbors=38))])\n",
        "knn_mod = clf_knn_mod.fit(x_train,y_train)\n",
        "y_pred_KNN = knn_mod.predict(x_test)\n",
        "accuracy_score(y_test, y_pred_KNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIN77a-ZqOOo"
      },
      "source": [
        "clf_knn_mod.predict(['dear ricardoNUMBER cost effective direct email advertising promote your business for as low as NUMBE'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lwFO6HddZNd"
      },
      "source": [
        "confusion_matrix(y_test, y_pred_KNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCNSTjPpvz4t"
      },
      "source": [
        "### 5.2 - Decision Tree Model\n",
        "Se escogió el modelo Decision Tree para contar con un modelo simple, la finalidad principal de usar este modelo es ver qué impacto tiene con nuestro dataset y poder compararlo con los demás modelos a usar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO7Sk2ILvz4t"
      },
      "source": [
        "### 5.3 - XGBoost Model\n",
        "Siguiendo la linea de la investigación realizada, encontramos en el modelo de XGboost una opción más sofisticada y mas controlable de Logistic Regression. Por ello la proponemos como una opción mejorada del modelo anterior que nos permita jugar más con los hiper-parámetros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJqxc77AqOOo"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "clf_xgb = Pipeline([('tfidf', TfidfVectorizer()),('Xgb', xgb.XGBClassifier(learning_rate =0.1,\n",
        "\t\t\t\t\t\t\t\t\tn_estimators=1000,\n",
        "\t\t\t\t\t\t\t\t\tmax_depth=5,\n",
        "\t\t\t\t\t\t\t\t\tmin_child_weight=1,\n",
        "\t\t\t\t\t\t\t\t\tgamma=0,\n",
        "\t\t\t\t\t\t\t\t\tsubsample=0.8,\n",
        "\t\t\t\t\t\t\t\t\tcolsample_bytree=0.8,\n",
        "\t\t\t\t\t\t\t\t\tobjective= 'binary:logistic',\n",
        "\t\t\t\t\t\t\t\t\tscale_pos_weight=1))])\n",
        "clf_xgb.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uap1xuPYqOOo"
      },
      "source": [
        "result_xgb_ac=[]\n",
        "result_xgb_n_estimators=[]\n",
        "for i in range(0,200,10):\n",
        "    clf_xgb_tmp = Pipeline([('tfidf', TfidfVectorizer()),('Xgb', xgb.XGBClassifier(learning_rate =0.1,\n",
        "\t\t\t\t\t\t\t\t\tn_estimators=i,\n",
        "\t\t\t\t\t\t\t\t\tmax_depth=5,\n",
        "\t\t\t\t\t\t\t\t\tmin_child_weight=1,\n",
        "\t\t\t\t\t\t\t\t\tgamma=0,\n",
        "\t\t\t\t\t\t\t\t\tsubsample=0.8,\n",
        "\t\t\t\t\t\t\t\t\tcolsample_bytree=0.8,\n",
        "\t\t\t\t\t\t\t\t\tobjective= 'binary:logistic',\n",
        "\t\t\t\t\t\t\t\t\tscale_pos_weight=1))])\n",
        "    clf_xgb_tmp.fit(x_train, y_train)\n",
        "    y_XGB = clf_xgb_tmp.predict(x_test)\n",
        "    aux_score = accuracy_score(y_test, y_XGB)\n",
        "    result_xgb_ac+=[aux_score]\n",
        "    result_xgb_n_estimators+=[i]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(result_xgb_n_estimators, result_xgb_ac, c='r')\n",
        "plt.plot(result_xgb_n_estimators, result_xgb_ac)\n",
        "plt.xlabel('N Estimators')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlim(0, 200)\n",
        "plt.ylim(0.5, 1.0)\n",
        "plt.title('accuracy vs. N Estimators')\n",
        "plt.show()\n",
        "print(\"Maximum accuracy: \",max(result_xgb_ac),\"at Estimator with N =\",result_xgb_n_estimators[result_xgb_ac.index(max(result_xgb_ac))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS_2-a_DqOOo"
      },
      "source": [
        "clf_xgb_mod = Pipeline([('tfidf', TfidfVectorizer()),('Xgb', xgb.XGBClassifier(learning_rate =0.1,\n",
        "\t\t\t\t\t\t\t\t\tn_estimators=70,\n",
        "\t\t\t\t\t\t\t\t\tmax_depth=5,\n",
        "\t\t\t\t\t\t\t\t\tmin_child_weight=1,\n",
        "\t\t\t\t\t\t\t\t\tgamma=0,\n",
        "\t\t\t\t\t\t\t\t\tsubsample=0.8,\n",
        "\t\t\t\t\t\t\t\t\tcolsample_bytree=0.8,\n",
        "\t\t\t\t\t\t\t\t\tobjective= 'binary:logistic',\n",
        "\t\t\t\t\t\t\t\t\tscale_pos_weight=1))])\n",
        "clf_xgb_mod.fit(x_train, y_train)\n",
        "y_pred_XGB = clf_xgb_mod.predict(x_test)\n",
        "accuracy_score(y_test, y_pred_XGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeFQgTpwqOOo"
      },
      "source": [
        "clf_xgb_mod.predict(['NUMBER NUMBER NUMBER NUMBER NUMBER NUMBER NUMBER'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfnmxaeodSd2"
      },
      "source": [
        "confusion_matrix(y_test, y_pred_XGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-mjTWTwqOOo"
      },
      "source": [
        "### 5.4 - Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Ugdn_MqOOo"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "estimators = 1\n",
        "clf_rfst = Pipeline([('tfidf', TfidfVectorizer()),('clf_rfst', RandomForestClassifier(n_estimators=estimators, n_jobs=-1))])\n",
        "clf_rfst.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Z2oNjPTvPp"
      },
      "source": [
        "acc = []\n",
        "\n",
        "for i in range(1,400,10):\n",
        "    clf_rfst_aux = Pipeline([('tfidf', TfidfVectorizer()),('clf_rfst', RandomForestClassifier(n_estimators=i, n_jobs=-1))])\n",
        "    clf_rfst_aux.fit(x_train, y_train)\n",
        "    #neigh = KNeighborsClassifier(n_neighbors = i).fit(x_train_w_pca,y_train)\n",
        "    y_pred = clf_rfst_aux.predict(x_test)\n",
        "    acc.append(accuracy_score(y_test, y_pred))\n",
        "    \n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,41),acc,color = 'blue',linestyle='dashed', \n",
        "         marker='o',markerfacecolor='red', markersize=10);\n",
        "plt.title('accuracy vs. N Estimator')\n",
        "plt.xlabel('N')\n",
        "plt.ylabel('Accuracy')\n",
        "print(\"Maximum accuracy:\",max(acc),\"at N =\",(acc.index(max(acc))*10)+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSbARmnwWJV9"
      },
      "source": [
        "clf_rfst = Pipeline([('tfidf', TfidfVectorizer()),('clf_rfst', RandomForestClassifier(n_estimators=171, n_jobs=-1))])\n",
        "clf_rfst.fit(x_train, y_train)\n",
        "y_pred_rfst = clf_rfst.predict(x_test)\n",
        "accuracy_score(y_test, y_pred_rfst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an5a8VLvqOOp"
      },
      "source": [
        "clf_rfst.predict(['porn'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvJwl7-iqOOp"
      },
      "source": [
        "confusion_matrix(y_test, y_pred_rfst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS0hWboEZx2Z"
      },
      "source": [
        "### 5.5 - Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCFjdUpZZ4a2"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf_multiNB = Pipeline([('tfidf',TfidfVectorizer()), ('clf_multiNB', MultinomialNB())])\n",
        "clf_multiNB.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eozWYJrvaHKx"
      },
      "source": [
        "y_pred_multiNB = clf_multiNB.predict(x_test)\n",
        "accuracy_score(y_test, y_pred_multiNB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48o4R9WobHNA"
      },
      "source": [
        "clf_multiNB.predict(['porn'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCEHKTaWbK_h"
      },
      "source": [
        "confusion_matrix(y_test, y_pred_multiNB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02MpU5H1bUsY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCtvLkt_vz4u"
      },
      "source": [
        "dataTest = [df.iloc[600,0].lower(),df.iloc[601,0].lower()]\n",
        "testMSG = vec_datos.transform(dataTest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMep87qhvz4u"
      },
      "source": [
        "print(testMSG.toarray()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjLxs-levz4v"
      },
      "source": [
        "readyMSG= pd.DataFrame(testMSG.toarray(), columns=tf_idf_dataframe_smooth.iloc[:,:-1].columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsAEKJWmvz4v"
      },
      "source": [
        "readyMSG.iloc[1,:].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6LfRFfAvz4v"
      },
      "source": [
        "pca2 = PCA(n_components=2)\n",
        "\n",
        "principalComponents2 = pca2.fit_transform(readyMSG)\n",
        "principalDf2 = pd.DataFrame(data = principalComponents2\n",
        "             , columns = ['principal component 1', 'principal component 2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgtBCLCvvz4v"
      },
      "source": [
        "print(principalDf2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umrZp6q9vz4v"
      },
      "source": [
        "principalDf2.iloc[1,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXHvGeMm1kX8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoGAgPwl1lGc"
      },
      "source": [
        "### 5.6 - Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4U4c-LLw5TW",
        "outputId": "8320ba99-677d-413e-d0d2-d5e9e6061bea"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.pipeline import Pipeline\n",
        "clf = svm.SVC()\n",
        "clf_svm = Pipeline([('tfidf', TfidfVectorizer()),('Svm',svm.SVC())])\n",
        "clf_svm.fit(x_train, y_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('Svm',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                     probability=False, random_state=None, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN8rbBB21lGc"
      },
      "source": [
        "y_pred_svm = clf_svm.predict(x_test)\n",
        "accuracy_score(y_test, y_pred_svm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UCE5Umv1lGc"
      },
      "source": [
        "clf_svm.predict(['porn'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxFmOt3j1lGc"
      },
      "source": [
        "confusion_matrix(y_test, y_pred_svm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acPp3nXt1lGd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTyvuCm01lGd"
      },
      "source": [
        "dataTest = [df.iloc[600,0].lower(),df.iloc[601,0].lower()]\n",
        "testMSG = vec_datos.transform(dataTest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Hes4GM1lGd"
      },
      "source": [
        "print(testMSG.toarray()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKgfjje81lGd"
      },
      "source": [
        "readyMSG= pd.DataFrame(testMSG.toarray(), columns=tf_idf_dataframe_smooth.iloc[:,:-1].columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCP7R3N01lGd"
      },
      "source": [
        "readyMSG.iloc[1,:].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufdDOCP91lGd"
      },
      "source": [
        "pca2 = PCA(n_components=2)\n",
        "\n",
        "principalComponents2 = pca2.fit_transform(readyMSG)\n",
        "principalDf2 = pd.DataFrame(data = principalComponents2\n",
        "             , columns = ['principal component 1', 'principal component 2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-2eFN3b1lGd"
      },
      "source": [
        "print(principalDf2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aObZU2Kb1lGe"
      },
      "source": [
        "principalDf2.iloc[1,:]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}